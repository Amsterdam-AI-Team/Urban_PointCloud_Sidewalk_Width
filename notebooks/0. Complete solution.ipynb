{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4636d31d",
   "metadata": {},
   "source": [
    "# Filter all the points in the point cloud above sidewalk\n",
    "In the previous notebook we scraped and parsed sidewalk data in the form of polygons. With the help of this reference data, we can filter all the points in the point cloud cloud that are above the sidewalk. This preprocessing step is performed in this notebook to reduce the amount of points in the point cloud.\n",
    "\n",
    "If the input point cloud is partly labelled using the [Urban_PointCloud_Processing](https://github.com/Amsterdam-AI-Team/Urban_PointCloud_Processing) project its GROUND and ROAD labels are used to filter ground points; otherwise a separate ground filtering step is performed first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395bd7d8-8e00-4a61-9203-cc8940a0223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project src to path.\n",
    "import set_path\n",
    "\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pathlib\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import upcp.fusion as fusion\n",
    "import upcp.utils.ahn_utils as ahn_utils\n",
    "import upcp.utils.bgt_utils as bgt_utils\n",
    "import upcp.utils.log_utils as log_utils\n",
    "import upcp.utils.las_utils as las_utils\n",
    "from upcp.labels import Labels\n",
    "\n",
    "# Local imports\n",
    "import upc_sw.sw_utils as sw_utils\n",
    "from upc_sw.cluster2polygon import Cluster2Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc14917-e983-4dd3-92a6-1629907eddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data folders.\n",
    "ahn_data_folder = '../datasets/ahn/'\n",
    "bgt_data_file = '../datasets/bgt/bgt_voetpad.csv'\n",
    "pc_data_folder = '../datasets/pointclouds/'\n",
    "pc_file_prefix = 'processed'\n",
    "out_folder = '../datasets/obstacles/'\n",
    "CRS = 'epsg:28992'\n",
    "\n",
    "# Use existing labels in the point cloud, if present. Otherwise, perform ground filter step.\n",
    "use_existing_labels = True\n",
    "ground_labels = [Labels.GROUND, Labels.ROAD] # Which labels to use as ground.\n",
    "\n",
    "# Distance threshold for static obstacles.\n",
    "dist_threshold = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc635969-121c-4890-afae-551a2f087815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AHN elevation reader.\n",
    "ahn_reader = ahn_utils.NPZReader(data_folder=ahn_data_folder, caching=False)\n",
    "\n",
    "# Sidewalk polygon reader.\n",
    "sw_poly_reader = bgt_utils.BGTPolyReader(bgt_file=bgt_data_file)\n",
    "\n",
    "# Ground fuser using pre-processed AHN data. Used when no existing labels are available.\n",
    "ground_fuser = fusion.AHNFuser(Labels.GROUND, ahn_reader=ahn_reader,\n",
    "                               target='ground', epsilon=0.2, refine_ground=False)\n",
    "\n",
    "# Convert 3D Obstacle blobs to 2D polygons using a clustering algorithm.\n",
    "# Set use_concave=False to use the faster convex hull.\n",
    "# Change alpha to determine the 'concaveness' of the concave hull, with 0 being convex.\n",
    "c2p = Cluster2Polygon(min_component_size=100, grid_size=0.05, use_concave=True, concave_min_area=0., alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c305d44-fe83-4d04-a7c2-a315810705c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders for obstacle files.\n",
    "for run in ['run1', 'run2']:\n",
    "    new_path = f'{pc_data_folder}obstacles_{run}'\n",
    "    pathlib.Path(new_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2d40dc-9b55-4ae2-9f3f-d9a5cdcf633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all tilecodes for which we have two runs.\n",
    "all_tiles = (las_utils.get_tilecodes_from_folder(f'{pc_data_folder}run1/', las_prefix=pc_file_prefix)\n",
    "             .union(las_utils.get_tilecodes_from_folder(f'{pc_data_folder}run2/', las_prefix=pc_file_prefix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a68b233-1d5c-4229-9412-75da04c61436",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dec7e63-8877-4ed6-873d-ffd43d16d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_tqdm = tqdm(all_tiles, unit='tile', smoothing=0)\n",
    "\n",
    "for tilecode in tile_tqdm:\n",
    "    tile_tqdm.set_postfix_str(tilecode)\n",
    "    print(f'Processing tile {tilecode}...')\n",
    "    for run in ['run1', 'run2']:\n",
    "        file = f'{pc_data_folder}{run}/{pc_file_prefix}_{tilecode}.laz'\n",
    "        \n",
    "        # Load pointcloud data.\n",
    "        points, labels = sw_utils.read_las(file, extra_val='label')\n",
    "        obstacle_mask = np.zeros((len(points),), dtype=bool)\n",
    "        \n",
    "        # Load ground points.\n",
    "        if use_existing_labels and np.count_nonzero(labels) > 0:\n",
    "            print('Using labels found in pointcloud file.')\n",
    "            ground_mask = sw_utils.create_label_mask(labels, target_labels=ground_labels)\n",
    "        else:\n",
    "            mask = np.ones((len(points),), dtype=bool)\n",
    "            ground_mask = ground_fuser.get_label_mask(points, labels, mask, tilecode)\n",
    "        \n",
    "        # Extract points aboves sidewalk.\n",
    "        # mask_ids = np.where(~ground_mask)[0]\n",
    "        sw_mask = sw_utils.sidewalk_clip(\n",
    "                                points[~ground_mask], tilecode, sw_poly_reader=sw_poly_reader,\n",
    "                                ahn_reader=ahn_reader, max_height=2.0)\n",
    "        obstacle_mask[~ground_mask] = sw_mask\n",
    "        \n",
    "        # Save the new point cloud\n",
    "        out_file = f'{pc_data_folder}obstacles_{run}/obst_{tilecode}.laz'\n",
    "        sw_utils.write_las(points[obstacle_mask], out_file, values=labels[obstacle_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce07d7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16914932-b9ef-4460-8b99-41b574b1aa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_tqdm = tqdm(all_tiles, unit='tile', smoothing=0)\n",
    "\n",
    "obstacle_df = gpd.GeoDataFrame(columns=['tilecode', 'type', 'geometry'], geometry='geometry', crs=CRS)\n",
    "\n",
    "for tilecode in tile_tqdm:\n",
    "    tile_tqdm.set_postfix_str(tilecode)\n",
    "    \n",
    "    # Read point cloud with M3C2 distances\n",
    "    in_file = f'{pc_data_folder}m3c2/m3c2_{tilecode}.laz'\n",
    "    points, m3c2_distance = sw_utils.read_las(in_file, extra_val='M3C2_distance', extra_val_dtype='float32')\n",
    "\n",
    "    # Filter for static points\n",
    "    mask = np.abs(m3c2_distance) < m3c2_threshold\n",
    "    \n",
    "    # Get the polygons\n",
    "    polys, types = c2p.get_obstacle_polygons(points[mask])\n",
    "    data = {'tilecode': [tilecode]*len(polys),\n",
    "            'type': types,\n",
    "            'geometry': [Polygon(p) for p in polys]}\n",
    "    obstacle_df = obstacle_df.append(gpd.GeoDataFrame(data, geometry='geometry', crs=CRS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09902453-d99b-4c77-918d-feff19170e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the obstacle GeoDataFrame.\n",
    "pathlib.Path(out_folder).mkdir(parents=True, exist_ok=True)\n",
    "obstacle_df.to_file(f'{out_folder}obstacles.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c78d20-3d3f-40b4-9a0c-eaca10efcaea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8328c16a-5526-4cc7-9341-32b973a4cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "points, labels = sw_utils.read_las('../datasets/pointclouds/obstacles_run1/obst_2386_9702.laz', extra_val='label')\n",
    "c2p = Cluster2Polygon(min_component_size=100, grid_size=0.05, use_concave=True, concave_min_area=0., alpha=1)\n",
    "polys, types = c2p.get_obstacle_polygons(points)\n",
    "obstacle_df1 = gpd.GeoDataFrame({'geometry': polys}, crs=CRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e875fe1-9df7-4abb-b6cc-6a8d33dca9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "points, labels = sw_utils.read_las('../datasets/pointclouds/obstacles_run2/obst_2386_9702.laz', extra_val='label')\n",
    "c2p = Cluster2Polygon(min_component_size=100, grid_size=0.05, use_concave=True, concave_min_area=0., alpha=1)\n",
    "polys, types = c2p.get_obstacle_polygons(points)\n",
    "obstacle_df2 = gpd.GeoDataFrame({'geometry': polys}, crs=CRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf07d925-4da2-473a-ad44-580f91afa014",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "obstacle_df1.plot(ax=ax, color='green', alpha=0.5)\n",
    "obstacle_df2.plot(ax=ax, color='grey', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7a6aee-aaa5-4244-a474-21783021a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsd_dist(g):\n",
    "    dists = [g.geometry.hausdorff_distance(g2) for g2 in obstacle_df2.geometry]\n",
    "    return min(dists)\n",
    "\n",
    "obstacle_df1['min_hsd'] = obstacle_df1.progress_apply(hsd_dist, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16369179-5e66-404b-9545-48dfb329f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "divider = make_axes_locatable(ax)\n",
    "\n",
    "cax = divider.append_axes('right', size='4%', pad=0.2)\n",
    "cax.set_xlabel('hsd')\n",
    "\n",
    "obstacle_df1.plot(column=obstacle_df1['min_hsd'], legend=True, ax=ax, cax=cax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c246919-07eb-49fa-ad96-1c3f2bb695c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
