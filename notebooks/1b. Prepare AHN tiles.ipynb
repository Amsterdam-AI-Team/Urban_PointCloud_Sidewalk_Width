{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5fdd96c-6724-4c1f-83aa-93b363895ed7",
   "metadata": {},
   "source": [
    "# AHN tiles download and preprocessing\n",
    "\n",
    "This notebook downloads and pre-processes AHN elevation data for a given set of point cloud tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c91cf31-0ece-4291-b074-86931e180c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely.geometry as sg\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import pathlib\n",
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import sys\n",
    "import csv\n",
    "import laspy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from upcp.preprocessing import ahn_preprocessing\n",
    "from upcp.utils import las_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d0b6c7-b8e3-4152-b216-27945a373ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SETTINGS ###\n",
    "\n",
    "# Location of point cloud tiles for which AHN data should be generated\n",
    "pc_folder = '../datasets/pointclouds/run1/'\n",
    "\n",
    "# AHN output settings\n",
    "ahn_version = 'ahn3'  # Either ahn3 or ahn4\n",
    "ahn_resolution = 0.1  # Resolution for the .npz data\n",
    "ahn_data_folder = '../datasets/ahn/'  # Location where AHN data will be stored\n",
    "ahn_subtile_folder = f'{ahn_data_folder}{ahn_version}_subtiles/'  # Location to store AHN subtiles\n",
    "\n",
    "# https://geotiles.nl/ data source\n",
    "base_url = f'https://geotiles.nl/{str.upper(ahn_version)}_T/'\n",
    "\n",
    "# Create folders if they don't exist\n",
    "pathlib.Path(ahn_data_folder).mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(ahn_subtile_folder).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da949d84-2256-4468-b62b-a5d143eceee6",
   "metadata": {},
   "source": [
    "## Get a list of AHN3 tile names and coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58869e4e-50bb-4abf-911b-2636c1809ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates_features(features):\n",
    "    def map_fun(feature):\n",
    "        minx = feature[\"geometry\"][\"coordinates\"][0][0][0][0]  # multipolygon causing the nesting\n",
    "        miny = feature[\"geometry\"][\"coordinates\"][0][0][0][1]\n",
    "        maxx = feature[\"geometry\"][\"coordinates\"][0][0][2][0]\n",
    "        maxy = feature[\"geometry\"][\"coordinates\"][0][0][2][1]\n",
    "        bladnr = feature[\"properties\"][\"bladnr\"]\n",
    "        return bladnr, int(np.around(minx)), int(np.around(miny)), int(np.around(maxx)), int(np.around(maxy))\n",
    "    return [map_fun(feature) for feature in features]\n",
    "\n",
    "url = \"https://geodata.nationaalgeoregister.nl/ahn3/wfs?request=GetFeature&typename=ahn3:ahn3_bladindex&outputFormat=json\"\n",
    "with urlopen(url) as response:\n",
    "    json_string = response.read()\n",
    "data = json.loads(json_string)\n",
    "coordinates = get_coordinates_features(data[\"features\"])\n",
    "\n",
    "with open(f'{ahn_data_folder}ahn3_tegels.csv', 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow([\"bladnr\", \"min_x\", \"min_y\", \"max_x\", \"max_y\"])\n",
    "    for coord in coordinates:\n",
    "        csv_writer.writerow(coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc1054f-2a2b-45a3-9f80-17daed51bd97",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download AHN sub-tiles corresponding to required area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f6581e-0b05-4120-96ea-2bc83f04c987",
   "metadata": {},
   "source": [
    "### Load AHN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebdc4a6-1b21-4bf0-9052-e6cde88ed13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ahn_geometry(row):\n",
    "    x1, y1, x2, y2 = row[['min_x', 'min_y', 'max_x', 'max_y']]\n",
    "    return sg.box(x1, y1, x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fa35bd-eb73-47bb-b349-730c8aaa260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AHN data\n",
    "ahn_df = pd.read_csv(f'{ahn_data_folder}ahn3_tegels.csv')\n",
    "ahn_gdf = gpd.GeoDataFrame({'bladnr': ahn_df['bladnr'],\n",
    "                            'geometry': ahn_df.progress_apply(get_ahn_geometry, axis=1)},\n",
    "                           geometry='geometry')\n",
    "ahn_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196fe9ba-e43d-41e1-8808-72fa3b6ae694",
   "metadata": {},
   "source": [
    "### Find AHN subtiles that cover the target area based on CycloMedia tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932dd41e-750c-4ef9-b0b7-58a162ed7b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tile_geometry(row):\n",
    "    x, y = row[['RD_X', 'RD_Y']]\n",
    "    return sg.box(x, y, x+50, y+50)\n",
    "\n",
    "def get_tilecode_poly(tilecode):\n",
    "    ((x1, y2),(x2, y1)) = las_utils.get_bbox_from_tile_code(tilecode)\n",
    "    return sg.box(x1, y1, x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bad881-9599-43a6-a2bb-0d01691222cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of target point cloud tiles\n",
    "pc_tiles = list(las_utils.get_tilecodes_from_folder(pc_folder))\n",
    "\n",
    "# Generate a GeoDataFrame\n",
    "pc_tiles_gdf = gpd.GeoDataFrame({'tilecode': pc_tiles,\n",
    "                                 'geometry': [get_tilecode_poly(tc) for tc in pc_tiles]})\n",
    "\n",
    "# Generate a merged GeoDataFrame for effiency\n",
    "merged_poly = pc_tiles_gdf.unary_union\n",
    "if type(merged_poly) == sg.Polygon:\n",
    "    merged_poly = sg.MultiPolygon([merged_poly])\n",
    "merged_pc_tiles = gpd.GeoDataFrame({'geometry': [geom for geom in merged_poly.geoms]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71baa75-0b5c-4106-9e59-d38fadc95280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter ahn data based on merged target shapes\n",
    "ahn_gdf['used'] = ahn_gdf.apply(lambda row: (merged_pc_tiles.intersects(row.geometry) \n",
    "                                             & ~merged_pc_tiles.touches(row.geometry)).any(),\n",
    "                                axis=1)\n",
    "ahn_gdf = ahn_gdf[ahn_gdf['used']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dddebde-35c4-4296-8d03-936ab52ca12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the result\n",
    "fig, ax = plt.subplots(1)\n",
    "ahn_gdf.plot(ax=ax, edgecolor=\"black\", linewidth=0.4, alpha=0.25)\n",
    "merged_pc_tiles.plot(ax=ax)\n",
    "ax.set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee12e52-8ddf-49d9-b61d-87ffa5c2952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide AHN tile into 25 subtiles of 1x1.25 km each (see https://geotiles.nl/)\n",
    "Wst = 1000  # Width of subtile\n",
    "Hst = 1250  # Height of subtile\n",
    "\n",
    "subtile_gdf = []\n",
    "\n",
    "for _, row in ahn_gdf.iterrows():\n",
    "    (x_min, y_min, x_max, y_max) = row.geometry.bounds\n",
    "    xs = np.arange(x_min, x_max, Wst, dtype=int)\n",
    "    ys = np.arange(y_max - Hst, y_min-0.01, -Hst, dtype=int)\n",
    "    tiles = [sg.box(x, y, x+Wst, y+Hst) for y in ys for x in xs]\n",
    "    subtile_gdf.append(gpd.GeoDataFrame({'bladnr': [row.bladnr]*len(tiles),\n",
    "                                         'subtile': range(1, len(tiles)+1),\n",
    "                                         'geometry': tiles}))\n",
    "\n",
    "subtile_gdf = gpd.GeoDataFrame(pd.concat(subtile_gdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42228bb8-41ca-418e-8d24-36506e08f83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only subtiles that contain the target point cloud tiles.\n",
    "subtile_gdf['used'] = subtile_gdf.apply(lambda row: (merged_pc_tiles.intersects(row.geometry) \n",
    "                                                     & ~merged_pc_tiles.touches(row.geometry)).any(),\n",
    "                                        axis=1)\n",
    "subtile_gdf = subtile_gdf[subtile_gdf['used']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97af5d5-f745-4941-8335-de7503b26e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the result\n",
    "fig, ax = plt.subplots(1)\n",
    "subtile_gdf.plot(ax=ax, edgecolor=\"black\", linewidth=0.4, alpha=0.25)\n",
    "merged_pc_tiles.plot(ax=ax)\n",
    "ax.set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11352d1-3f38-47de-8a7b-7483f0e0b479",
   "metadata": {},
   "source": [
    "### Download the AHN subtiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95eebfa-55f6-4ba2-9e5a-2b6dbf379055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_url(url, root, filename=None):\n",
    "    \"\"\"Download a file from a url and place it in root.\n",
    "    Args:\n",
    "        url (str): URL to download file from\n",
    "        root (str): Directory to place downloaded file in\n",
    "        filename (str, optional): Name to save the file under. If None, use the basename of the URL\n",
    "    \"\"\"\n",
    "\n",
    "    root = os.path.expanduser(root)\n",
    "    if not filename:\n",
    "        filename = os.path.basename(url)\n",
    "    fpath = os.path.join(root, filename)\n",
    "\n",
    "    os.makedirs(root, exist_ok=True) \n",
    "    \n",
    "    # make an HTTP request within a context manager\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        # check header to get content length, in bytes\n",
    "        total_length = int(r.headers.get(\"Content-Length\"))\n",
    "\n",
    "        # implement progress bar via tqdm\n",
    "        with tqdm.wrapattr(r.raw, \"read\", total=total_length, desc=\"\") as raw:\n",
    "            # save the output to a file\n",
    "            with open(fpath, 'wb') as output:\n",
    "                shutil.copyfileobj(raw, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f3fb40-19f6-4223-a992-7082561fb20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate file names\n",
    "subtile_gdf['filename'] = subtile_gdf.progress_apply(\n",
    "                                    lambda row: f\"{str.upper(row['bladnr'])}_{row['subtile']:02d}.LAZ\",\n",
    "                                    axis=1)\n",
    "\n",
    "# Get list of required files\n",
    "req_files = set(subtile_gdf['filename'].values)\n",
    "\n",
    "# First check if any of the files already exist\n",
    "current_files = set(file.name for file in pathlib.Path(ahn_subtile_folder).glob('*.LAZ'))\n",
    "req_files = req_files.difference(current_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bb8bcb-1ef9-474e-aeeb-8099765480d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the remaining files\n",
    "file_tqdm = tqdm(req_files, unit='file')\n",
    "for file in file_tqdm:\n",
    "    url = f'{base_url}{file}'\n",
    "    file_tqdm.set_postfix_str(url)\n",
    "    download_url(url, ahn_subtile_folder, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84606fb3-84e9-40db-8575-f79696e6d935",
   "metadata": {},
   "source": [
    "## Pre-process the AHN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ba0e8-79cb-4573-a91b-56e931dce5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_subtile(row):\n",
    "    target_df = subtile_gdf[subtile_gdf.contains(row.geometry)]\n",
    "    if len(target_df) == 0:  # Shouldn't happen\n",
    "        return None\n",
    "    else:\n",
    "        return target_df.iloc[0]['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09316a45-e01d-4807-bfd0-159db5349de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ahn_laz_folder = f'{ahn_data_folder}{ahn_version}_laz/'\n",
    "ahn_npz_folder = f'{ahn_data_folder}{ahn_version}_npz/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a034b99f-c029-46f9-a897-cd899be70691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match point cloud tiles to AHN subtiles\n",
    "pc_tiles_gdf['subtile'] = pc_tiles_gdf.progress_apply(match_subtile, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b677a17-9993-4dfd-b859-78e63c9d4ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate .laz tiles\n",
    "pbar = tqdm(total=len(pc_tiles_gdf))\n",
    "for subtile in pc_tiles_gdf['subtile'].unique():\n",
    "    ahn_cloud = laspy.read(f'{ahn_subtile_folder}{subtile}')\n",
    "    ahn_cloud = laspy.convert(ahn_cloud, point_format_id=3, file_version='1.2')\n",
    "    for pc_tile in pc_tiles_gdf[pc_tiles_gdf['subtile'] == subtile]['tilecode'].values:\n",
    "        pc_path = f'{pc_folder}dummy_{pc_tile}.laz'\n",
    "        ahn_preprocessing.clip_ahn_las_tile(ahn_cloud, pc_path, out_folder=ahn_laz_folder)\n",
    "        pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f600c3-b107-4b87-bd6f-5112c72c60d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate .npz data for all tiles\n",
    "files = list(pathlib.Path(ahn_laz_folder).glob('ahn_*.laz'))\n",
    "pathlib.Path(ahn_npz_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "file_tqdm = tqdm(files, unit='file', smoothing=0)\n",
    "for file in file_tqdm:\n",
    "    ahn_preprocessing.process_ahn_las_tile(\n",
    "                            file, out_folder=ahn_npz_folder,\n",
    "                            resolution=ahn_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfdf5e5-cfd8-4afb-ab51-1aa9fd8c7088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative, uses parallel processing\n",
    "!python ../../Urban_PointCloud_Processing/scripts/ahn_batch_processor.py --in_folder {ahn_laz_folder} --out_folder {ahn_npz_folder} --resume --workers 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d34a22-8541-47e8-b972-80b04247534d",
   "metadata": {},
   "source": [
    "## Clean-up\n",
    "\n",
    "In principle, you can now safely delete the AHN .laz files as they are no longer needed. However, the subtiles could be preserve to prevent having to download them again for nearby point cloud tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e017ae-5b36-412c-afa2-341c5b8ad2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The following folders can be deleted:')\n",
    "print(ahn_subtile_folder)\n",
    "print(ahn_laz_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e58d63-fdc1-47dd-bd4f-0b1a6569029d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
