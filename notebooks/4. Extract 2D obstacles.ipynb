{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e07af1a9",
   "metadata": {},
   "source": [
    "# Extract 2D obstacles\n",
    "Generate polygons for all static obstacles, and merge these with the sidewalk polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d2619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project src to path.\n",
    "import set_path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "import shapely.geometry as sg\n",
    "import shapely.ops as so\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from upcp.utils import bgt_utils\n",
    "from upcp.utils import csv_utils\n",
    "from upcp.utils import las_utils\n",
    "\n",
    "from upc_sw.cluster2polygon import Cluster2Polygon\n",
    "from upc_sw import sw_utils\n",
    "from upc_sw import poly_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813e7141-d0ac-4cce-9138-f7f7c689e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings  # temporary, to supress deprecationwarnings from shapely\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8143e7",
   "metadata": {},
   "source": [
    "## Create polygons of static obstacles\n",
    "In the previous notebook, we performed a change detection algorithm that calculated M3C2 distance for each point in the point cloud. Based on negative and positive threshold values we can filter for the static points in the point cloud. We then cluster these into individual obstacles and create bounding polygons for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c253e6b3-d2da-42b3-ab15-efb5dfb45ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SETTINGS ###\n",
    "\n",
    "CRS = 'epsg:28992'\n",
    "\n",
    "base_folder = '../../datasets/Accessibility_oost/'\n",
    "pc_data_folder = f'{base_folder}pointclouds/'\n",
    "bgt_folder = f'{base_folder}bgt/'\n",
    "out_folder = f'{base_folder}output/'\n",
    "\n",
    "# Scraped sidewalk and terras data for the area (see Notebook 1c)\n",
    "sidewalk_data = f'{bgt_folder}bgt_voetpad.gpkg'\n",
    "terras_data = f'{bgt_folder}terras_data.gpkg'\n",
    "obstacle_data = f'{bgt_folder}obstacle_data.gpkg'\n",
    "\n",
    "# Output file\n",
    "output_file = f'{out_folder}obstacles.gpkg'\n",
    "\n",
    "# Allow resume by saving intermediate output\n",
    "resume = True\n",
    "resume_batch_size = 10\n",
    "tmp_file = f'{out_folder}obst_tmp.pkl'\n",
    "\n",
    "# Distance threshold for static obstacles.\n",
    "m3c2_threshold = 0.2\n",
    "\n",
    "# Convert 3D Obstacle blobs to 2D polygons using a clustering algorithm.\n",
    "# Set use_concave=False to use the faster convex hull.\n",
    "# Change alpha to determine the 'concaveness' of the concave hull, with 0 being convex.\n",
    "c2p = Cluster2Polygon(min_component_size=100, grid_size=0.2, use_concave=True, concave_min_area=2.5, alpha=0.5)\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "pathlib.Path(out_folder).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0772aa69-493e-4303-83f1-ee882a12f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tiles = las_utils.get_tilecodes_from_folder(f'{pc_data_folder}m3c2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecffbe5-935b-4ba3-b6ca-2fbdc216c02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if resume and os.path.exists(tmp_file):\n",
    "    with open(tmp_file, 'rb') as f:\n",
    "        static_obstacles = pickle.load(f)\n",
    "        all_tiles = all_tiles - set(static_obstacles['tilecode'])\n",
    "else:\n",
    "    static_obstacles = {'tilecode': [],\n",
    "                        'type': [],\n",
    "                        'geometry': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f3ee01-2f2f-4b69-8a89-885a75ecc1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5cb680-47b9-4c58-8e83-e7b6bba6ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_tqdm = tqdm(all_tiles, unit='tile', smoothing=0)\n",
    "\n",
    "for i, tilecode in enumerate(tile_tqdm):\n",
    "    tile_tqdm.set_postfix_str(tilecode)\n",
    "    \n",
    "    # Read point cloud with M3C2 distances\n",
    "    in_file = f'{pc_data_folder}m3c2/m3c2_{tilecode}.laz'\n",
    "    points, m3c2_distance = sw_utils.read_las(in_file, extra_val='M3C2_distance', extra_val_dtype='float32')\n",
    "\n",
    "    # Filter for static points\n",
    "    mask = np.abs(m3c2_distance) < m3c2_threshold\n",
    "    \n",
    "    if np.count_nonzero(mask) > 0:\n",
    "        # Get the polygons\n",
    "        polygons, types = c2p.get_obstacle_polygons(points[mask])\n",
    "        static_obstacles['tilecode'].extend([tilecode]*len(polygons))\n",
    "        static_obstacles['type'].extend(types)\n",
    "        static_obstacles['geometry'].extend(polygons)\n",
    "    \n",
    "    if i % resume_batch_size == 0:\n",
    "        with open(tmp_file, 'wb') as f:\n",
    "            pickle.dump(static_obstacles, f)\n",
    "\n",
    "static_obstacles_gdf = gpd.GeoDataFrame(static_obstacles, geometry='geometry', crs=CRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da0d237-c8c9-4405-b3b0-a207d7843f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix invalid polygons\n",
    "static_obstacles_gdf['geometry'] = static_obstacles_gdf['geometry'].progress_apply(poly_utils.fix_invalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06821564-05df-4237-b3f7-5771c1c65034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the obstacle GeoDataFrame.\n",
    "if len(static_obstacles_gdf) > 0:\n",
    "    static_obstacles_gdf.to_file(output_file, driver='GPKG')\n",
    "else:\n",
    "    print('No obstacle data to write.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cbfd10",
   "metadata": {},
   "source": [
    "## Merge sidewalk polygons with obstacles\n",
    "The found obstacles (polygons) in the previous step are merged with the sidewalk polygons as interiors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72479ff-126a-4421-9112-d8b96f88b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SETTINGS ###\n",
    "\n",
    "merged_output_file = f'{out_folder}sidewalks_with_obstacles.gpkg'\n",
    "\n",
    "# Buffer width around the sidewalk to preserve its shape. Set to '0' to ignore this.\n",
    "sw_buffer = 0.01\n",
    "\n",
    "# Add padding around obstacles.\n",
    "obstacle_padding = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4f199f-ba99-485c-adcb-e0f29c190649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sidewalk data\n",
    "sidewalk_gdf = gpd.read_file(sidewalk_data, crs=CRS).set_index('ogc_fid')\n",
    "\n",
    "# Load the \"terras\" data\n",
    "if pathlib.Path(terras_data).is_file():\n",
    "    terras_gdf = gpd.read_file(terras_data, crs=CRS).set_index('id')\n",
    "else:\n",
    "    terras_gdf = gpd.GeoDataFrame({'geometry': []}, geometry='geometry', crs=CRS)\n",
    "\n",
    "# Load the obstacle data\n",
    "static_obstacles_gdf = gpd.read_file(output_file, crs=CRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bd59c7-4bce-4f46-a137-041b1cd59b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_obstacles(row):\n",
    "    # Subtract all obstacles that intersect the sidewalk polygon.\n",
    "    sw_ext, sw_int = poly_utils.extract_interior(row.geometry)\n",
    "    obst_poly = (static_obstacles_gdf[static_obstacles_gdf.intersects(sw_ext)]\n",
    "                 .buffer(obstacle_padding)\n",
    "                 .unary_union)\n",
    "    # TODO buffer also for terrace shapes?\n",
    "    terras_poly = terras_gdf[terras_gdf.intersects(sw_ext)].unary_union\n",
    "    merged_poly = so.unary_union([poly for poly in [obst_poly, terras_poly, sw_int] if poly is not None])\n",
    "    # TODO: do something with obstacle type?\n",
    "    if merged_poly is not None:\n",
    "        sw_ext = sw_ext.buffer(sw_buffer) - sw_ext.intersection(merged_poly)\n",
    "\n",
    "    return sw_ext\n",
    "\n",
    "sw_merged_gdf = sidewalk_gdf.copy()\n",
    "sw_merged_gdf['geometry'] = sidewalk_gdf.progress_apply(merge_obstacles, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df878a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the merged sidewalk data.\n",
    "sw_merged_gdf.to_file(merged_output_file, driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec05fbe-f0a7-47d9-b9e0-0744d7ac2151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
