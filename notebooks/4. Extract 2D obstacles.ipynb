{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e07af1a9",
   "metadata": {},
   "source": [
    "# Extract 2D obstacles\n",
    "Generate polygons for all static obstacles, and merge these with the sidewalk polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d2619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project src to path.\n",
    "import set_path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "import shapely.geometry as sg\n",
    "import shapely.ops as so\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from upcp.utils import bgt_utils\n",
    "from upcp.utils import csv_utils\n",
    "from upcp.utils import las_utils\n",
    "\n",
    "from upc_sw.cluster2polygon import Cluster2Polygon\n",
    "from upc_sw import sw_utils\n",
    "from upc_sw import poly_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813e7141-d0ac-4cce-9138-f7f7c689e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings  # temporary, to supress deprecationwarnings from shapely\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8143e7",
   "metadata": {},
   "source": [
    "## Create polygons of static obstacles\n",
    "In the previous notebook, we performed a change detection algorithm that calculated M3C2 distance for each point in the point cloud. Based on negative and positive threshold values we can filter for the static points in the point cloud. We then cluster these into individual obstacles and create bounding polygons for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c253e6b3-d2da-42b3-ab15-efb5dfb45ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SETTINGS ###\n",
    "\n",
    "CRS = 'epsg:28992'\n",
    "\n",
    "base_folder = '../../datasets/Stadsdelen/'\n",
    "pc_data_folder = 'pointclouds/'\n",
    "bgt_folder = 'bgt/'\n",
    "out_folder = 'output/'\n",
    "\n",
    "# Output file\n",
    "output_file = f'{out_folder}obstacles.gpkg'\n",
    "\n",
    "# Which stadsdelen to include\n",
    "stadsdelen = ['centrum', 'haven', 'nieuw_west', 'noord', 'oost', 'west', 'zuid', 'zuid_oost']\n",
    "\n",
    "# Allow resume by saving intermediate output\n",
    "resume = True\n",
    "resume_batch_size = 100\n",
    "tmp_file = f'{out_folder}obst_tmp.pkl'\n",
    "\n",
    "# Distance threshold for static obstacles.\n",
    "m3c2_threshold = 0.2\n",
    "\n",
    "# Convert 3D Obstacle blobs to 2D polygons using a clustering algorithm.\n",
    "# Set use_concave=False to use the faster convex hull.\n",
    "# Change alpha to determine the 'concaveness' of the concave hull, with 0 being convex.\n",
    "c2p = Cluster2Polygon(min_component_size=100, grid_size=0.2, use_concave=True, concave_min_area=2.5, alpha=0.5)\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "for stdsdl in stadsdelen:\n",
    "    new_path = pathlib.Path(base_folder) / stdsdl / out_folder\n",
    "    new_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecffbe5-935b-4ba3-b6ca-2fbdc216c02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tiles = {'stadsdeel': [],\n",
    "             'tilecode': []}\n",
    "\n",
    "for stdsdl in stadsdelen:\n",
    "    # If gpkg file exists, assume folder is done.\n",
    "    out_path = pathlib.Path(base_folder) / stdsdl / output_file\n",
    "    if resume and os.path.exists(out_path):\n",
    "        continue\n",
    "    \n",
    "    path = pathlib.Path(base_folder) / stdsdl / pc_data_folder / 'm3c2'\n",
    "    tiles = las_utils.get_tilecodes_from_folder(path, las_prefix='m3c2')\n",
    "    \n",
    "    # Check if tmp_file exists.\n",
    "    tmp_path = pathlib.Path(base_folder) / stdsdl / tmp_file\n",
    "    if resume and os.path.exists(tmp_path):\n",
    "        with open(tmp_path, 'rb') as f:\n",
    "            static_obstacles = pickle.load(f)\n",
    "            tiles = tiles - set(static_obstacles['tilecode'])\n",
    "            static_obstacles = None\n",
    "    \n",
    "    tiles = list(tiles)\n",
    "    tiles.sort()\n",
    "    all_tiles['stadsdeel'].extend([stdsdl]*len(tiles))\n",
    "    all_tiles['tilecode'].extend(tiles)\n",
    "\n",
    "all_tiles = pd.DataFrame(all_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5cb680-47b9-4c58-8e83-e7b6bba6ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_tqdm = tqdm(total=len(all_tiles), unit='tile', smoothing=0)\n",
    "\n",
    "for part_df in all_tiles.groupby(['stadsdeel']):\n",
    "    stdsdl = part_df[0]\n",
    "    \n",
    "    tmp_path = pathlib.Path(base_folder) / stdsdl / tmp_file\n",
    "    if resume and os.path.exists(tmp_path):\n",
    "        with open(tmp_path, 'rb') as f:\n",
    "            static_obstacles = pickle.load(f)\n",
    "    else:\n",
    "        static_obstacles = {'tilecode': [],\n",
    "                            'type': [],\n",
    "                            'geometry': []}\n",
    "\n",
    "    # TODO: parallelize this inner loop\n",
    "    for i, row in part_df[1].reset_index().iterrows():\n",
    "        tilecode = row['tilecode']\n",
    "        tile_tqdm.set_postfix_str(f'{stdsdl}/{tilecode}')\n",
    "\n",
    "        # Read point cloud with M3C2 distances\n",
    "        in_file = pathlib.Path(base_folder) / stdsdl / pc_data_folder / 'm3c2' / f'm3c2_{tilecode}.laz'\n",
    "        points, m3c2_distance = sw_utils.read_las(in_file, extra_val='M3C2_distance', extra_val_dtype='float32')\n",
    "\n",
    "        # Filter for static points\n",
    "        mask = np.abs(m3c2_distance) < m3c2_threshold\n",
    "\n",
    "        if np.count_nonzero(mask) > 0:\n",
    "            # Get the polygons\n",
    "            polygons, types = c2p.get_obstacle_polygons(points[mask])\n",
    "            static_obstacles['tilecode'].extend([tilecode]*len(polygons))\n",
    "            static_obstacles['type'].extend(types)\n",
    "            static_obstacles['geometry'].extend(polygons)\n",
    "\n",
    "        if i % resume_batch_size == 0:\n",
    "            with open(tmp_path, 'wb') as f:\n",
    "                pickle.dump(static_obstacles, f)\n",
    "        \n",
    "        tile_tqdm.update(1)\n",
    "\n",
    "    static_obstacles_gdf = gpd.GeoDataFrame(static_obstacles, geometry='geometry', crs=CRS)\n",
    "    static_obstacles = None\n",
    "    \n",
    "    # Fix invalid polygons\n",
    "    static_obstacles_gdf['geometry'] = static_obstacles_gdf['geometry'].apply(poly_utils.fix_invalid)\n",
    "    \n",
    "    # Save the obstacle GeoDataFrame.\n",
    "    out_path = pathlib.Path(base_folder) / stdsdl / output_file\n",
    "    if len(static_obstacles_gdf) > 0:\n",
    "        static_obstacles_gdf.to_file(out_path, driver='GPKG')\n",
    "        static_obstacles_gdf = None\n",
    "    \n",
    "    # Delete intermediate output\n",
    "    if os.path.exists(tmp_path):\n",
    "        os.remove(tmp_path)\n",
    "    \n",
    "\n",
    "tile_tqdm.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cbfd10",
   "metadata": {},
   "source": [
    "## Merge sidewalk polygons with obstacles\n",
    "The found obstacles (polygons) in the previous step are merged with the sidewalk polygons as interiors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72479ff-126a-4421-9112-d8b96f88b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SETTINGS ###\n",
    "\n",
    "merged_output_file = f'{out_folder}sidewalks_with_obstacles.gpkg'\n",
    "\n",
    "# Buffer width around the sidewalk to preserve its shape. Set to '0' to ignore this.\n",
    "sw_buffer = 0.01\n",
    "\n",
    "# Add padding around obstacles.\n",
    "obstacle_padding = 0.05\n",
    "\n",
    "# Add a buffer around BGT tree locations\n",
    "tree_buffer = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b044bf82-1496-42e9-9fbf-defdb7c5a133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_obstacles(row, static_obstacles_gdf, bgt_obst_gdf, obstacle_padding=obstacle_padding, sw_buffer=sw_buffer):\n",
    "    # Subtract all obstacles that intersect the sidewalk polygon.\n",
    "    sw_ext, sw_int = poly_utils.extract_interior(row.geometry)\n",
    "    obst_poly = (static_obstacles_gdf[static_obstacles_gdf.intersects(sw_ext)]\n",
    "                 .buffer(obstacle_padding)\n",
    "                 .unary_union)\n",
    "    # TODO buffer also for terrace shapes?\n",
    "    bgt_obst_poly = bgt_obst_gdf[bgt_obst_gdf.intersects(sw_ext)].unary_union\n",
    "    merged_poly = so.unary_union([poly for poly in [obst_poly, bgt_obst_poly, sw_int] if poly is not None])\n",
    "    # TODO: do something with obstacle type?\n",
    "    if merged_poly is not None:\n",
    "        sw_ext = sw_ext.buffer(sw_buffer) - sw_ext.intersection(merged_poly)\n",
    "\n",
    "    return sw_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af6cf2b-cb5e-4ad9-9628-fb1e86ece253",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stdsdl in stadsdelen:\n",
    "    # Scraped sidewalk and terras data for the area (see Notebook 1c)\n",
    "    sidewalk_data = pathlib.Path(base_folder) / stdsdl / bgt_folder / 'bgt_voetpad.gpkg'\n",
    "    terras_data = pathlib.Path(base_folder) / stdsdl / bgt_folder / 'terras_data.gpkg'\n",
    "    obstacle_data = pathlib.Path(base_folder) / stdsdl / bgt_folder / 'obstacle_data.gpkg'\n",
    "    \n",
    "    out_path = pathlib.Path(base_folder) / stdsdl / output_file\n",
    "    merged_path = pathlib.Path(base_folder) / stdsdl / merged_output_file\n",
    "\n",
    "    # Load the sidewalk data\n",
    "    sidewalk_gdf = gpd.read_file(sidewalk_data, crs=CRS).set_index('ogc_fid')\n",
    "\n",
    "    # Load the \"terras\" data\n",
    "    if pathlib.Path(terras_data).is_file():\n",
    "        bgt_obst_gdf = gpd.read_file(terras_data, crs=CRS).set_index('id')\n",
    "    else:\n",
    "        bgt_obst_gdf = gpd.GeoDataFrame({'geometry': []}, geometry='geometry', crs=CRS)\n",
    "\n",
    "    # Load the BGT obstacle data\n",
    "    if pathlib.Path(terras_data).is_file():\n",
    "        bgt_obst_gdf = pd.concat([bgt_obst_gdf,\n",
    "                                  gpd.read_file(obstacle_data, crs=CRS).set_index('ogc_fid')])\n",
    "\n",
    "    # Load the static obstacle data\n",
    "    static_obstacles_gdf = gpd.read_file(out_path, crs=CRS)\n",
    "\n",
    "    # Prepare (inflate) BGT obstacle shapes.\n",
    "    bgt_obst_gdf.loc[bgt_obst_gdf['naam']=='boom', 'geometry'] \\\n",
    "        = bgt_obst_gdf[bgt_obst_gdf['naam']=='boom'].buffer(tree_buffer)\n",
    "\n",
    "    # Do the merge.\n",
    "    sw_merged_gdf = sidewalk_gdf.copy()\n",
    "    sw_merged_gdf['geometry'] = sidewalk_gdf.progress_apply(lambda row: merge_obstacles(row, static_obstacles_gdf, bgt_obst_gdf), axis=1)\n",
    "\n",
    "    # Save the merged sidewalk data.\n",
    "    sw_merged_gdf.to_file(merged_path, driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc77c1c-2e57-4469-ba10-f814714afab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
