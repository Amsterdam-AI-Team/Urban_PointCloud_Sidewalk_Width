{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Compute sidewalk width\n",
        "Using centerline extraction (also called skeleton line, axis line, or medial line extraction)"
      ],
      "metadata": {},
      "id": "5f034096"
    },
    {
      "cell_type": "code",
      "source": [
        "# Select where to run notebook: \"azure\" or \"local\"\n",
        "my_run = \"azure\"\n",
        "\n",
        "# Select whether or not to do parallel processing\n",
        "parallel = True"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692186082426
        }
      },
      "id": "957e87cf-9118-433c-b1e8-d7aabdcacd45"
    },
    {
      "cell_type": "code",
      "source": [
        "import set_path  # add project src to path\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import pathlib\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "tqdm_notebook.pandas()\n",
        "import shapely.ops as so\n",
        "import shapely.geometry as sg\n",
        "\n",
        "import upcp.utils.bgt_utils as bgt_utils\n",
        "import upcp.utils.las_utils as las_utils\n",
        "\n",
        "import upc_sw.poly_utils as poly_utils\n",
        "\n",
        "if my_run == \"azure\":\n",
        "    import config_azure as cf\n",
        "elif my_run == \"local\":\n",
        "    import config as cf\n",
        "\n",
        "if parallel:\n",
        "    import dask_geopandas as dgpd\n",
        "    from dask.diagnostics import ProgressBar\n",
        "    pbar = ProgressBar()\n",
        "    pbar.register()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1692186113536
        }
      },
      "id": "071158b6"
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings  # temporary, to supress deprecationwarnings from shapely\n",
        "warnings.filterwarnings('ignore')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1692185119358
        }
      },
      "id": "efc1defc-cc76-4d8b-82d8-ae13a3229f2e"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create folder if it doesn't exist\n",
        "pathlib.Path(cf.out_folder).mkdir(parents=True, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692185049546
        }
      },
      "id": "f4ee4ee6-876a-49d0-a02a-f196338c3f33"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read the sidewalk and obstacle data"
      ],
      "metadata": {},
      "id": "9a555a6e"
    },
    {
      "cell_type": "code",
      "source": [
        "# Read sidewalk with obstacle data\n",
        "df = gpd.read_file(cf.obstacle_file, geometry='geometry', crs=cf.CRS)\n",
        "\n",
        "if cf.merge_sidewalks:\n",
        "    # Merge sidewalk polygons\n",
        "    df = gpd.GeoDataFrame(geometry=gpd.GeoSeries([geom for geom in df.unary_union.geoms]), crs=cf.CRS)\n",
        "    df['ogc_fid'] = range(0, len(df))  \n",
        "    \n",
        "else:\n",
        "    # Explode MultiPolygons into their parts\n",
        "    df = df.explode(index_parts=False)\n",
        "\n",
        "# Ignore sidewalk polygons that are too small\n",
        "df = df[df.area > cf.min_area_size]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1692186169464
        }
      },
      "id": "2f981e72"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate width along centerline segments"
      ],
      "metadata": {},
      "id": "972a8ee2"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_points_on_line(line, distance_delta):  \n",
        "    # Generate equidistant points\n",
        "    distances = np.arange(0, line.length, distance_delta)\n",
        "    points = sg.MultiPoint([line.interpolate(distance) for distance in distances])\n",
        "    return points\n",
        "\n",
        "def split_line_by_points(line, points, tolerance: float=0.001):\n",
        "    return so.split(so.snap(line, points, tolerance), points)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1692186169644
        }
      },
      "id": "b3d9e7fe"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_segments_width_cut(row, max_seg_length):\n",
        "    # Get centerlines.\n",
        "    cl = poly_utils.get_centerlines(row.geometry)\n",
        "    # Merge linestrings.\n",
        "    cl = so.linemerge(cl)\n",
        "    # Remove short line ends and dead-ends.\n",
        "    cl = poly_utils.remove_short_lines(cl, cf.min_se_length)\n",
        "    # Simplify lines.\n",
        "    cl = cl.simplify(cf.simplify_tolerance, preserve_topology=True)\n",
        "    # Segment lines \n",
        "    segments_long = poly_utils.get_segments(cl)   \n",
        "    # Cut segments (with maximum segment length)\n",
        "    segments = []\n",
        "    for seg in segments_long:\n",
        "        points_on_line = get_points_on_line(seg, max_seg_length)\n",
        "        seg_cut = split_line_by_points(seg, points_on_line)\n",
        "        segments.extend(seg_cut)\n",
        "    # Compute avg and min width per cut segment   \n",
        "    avg_width, min_width = poly_utils.get_avg_width(\n",
        "                    row.geometry, segments, cf.width_resolution, cf.width_precision)\n",
        "    return {'segments_long': segments_long, 'segments': segments, \n",
        "            'avg_width': avg_width, 'min_width': min_width, 'sidewalk_id': row.ogc_fid}      "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1692186319769
        }
      },
      "id": "892ba063"
    },
    {
      "cell_type": "code",
      "source": [
        "# if you get an error here, make sure you use tqdm>=4.61.2\n",
        "if parallel:\n",
        "    ddf = dgpd.from_geopandas(df, npartitions=24)\n",
        "    segment_df = pd.DataFrame((ddf.apply(get_segments_width_cut, \n",
        "                                         max_seg_length=cf.max_seg_length,\n",
        "                                         axis=1, meta=(object)).compute().values.tolist()))\n",
        "else:\n",
        "    segment_df = pd.DataFrame(df.progress_apply(get_segments_width_cut, \n",
        "                                                max_seg_length=cf.max_seg_length,                                                     \n",
        "                                                axis=1).values.tolist())\n",
        "\n",
        "with open(cf.tmp_file, 'wb') as f:\n",
        "    pickle.dump(segment_df.to_dict(), f)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1692188502097
        }
      },
      "id": "4984add4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explode into individual segments"
      ],
      "metadata": {},
      "id": "ce4c024b-6c64-405c-a593-b1a90b8dfd52"
    },
    {
      "cell_type": "code",
      "source": [
        "segment_df = pd.concat([gpd.GeoDataFrame({'geometry': row.segments,\n",
        "                                          'avg_width': row.avg_width,\n",
        "                                          'min_width': row.min_width,\n",
        "                                          'sidewalk_id': row.sidewalk_id} \n",
        "                                        )\n",
        "                         for _, row in segment_df.iterrows()],\n",
        "                       ignore_index=True)\n",
        "segment_df.set_crs(crs=cf.CRS, inplace=True);\n",
        "\n",
        "with open(cf.tmp_file, 'wb') as f:\n",
        "    pickle.dump(segment_df.to_dict(), f)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1692188554838
        }
      },
      "id": "84732b22-e29a-4f04-9158-a4fa30e22e2a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check coverage of point cloud data on sidewalks"
      ],
      "metadata": {},
      "id": "b12dd85c"
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of all tilecodes for which we have two runs.\n",
        "if my_run == \"azure\":\n",
        "    df1 = pd.read_csv(f'{cf.pc_data_folder}AMS_run1_tiles_list.csv')\n",
        "    df2 = pd.read_csv(f'{cf.pc_data_folder}AMS_run2_tiles_list.csv')\n",
        "    all_tiles = set(list(df1['tilecode'])).intersection(set(list(df2['tilecode'])))\n",
        "elif my_run == \"local\":\n",
        "    all_tiles = (las_utils.get_tilecodes_from_folder(f'{cf.pc_data_folder}run1/', las_prefix='processed')\n",
        "                .intersection(las_utils.get_tilecodes_from_folder(f'{cf.pc_data_folder}run2/', las_prefix='processed')))\n",
        "\n",
        "# Get polygon of all tiles\n",
        "all_tiles_poly = so.unary_union([poly_utils.tilecode_to_poly(tile) for tile in all_tiles])\n",
        "\n",
        "# Check whether segments are within polygon\n",
        "segment_df['pc_coverage'] = segment_df.intersects(all_tiles_poly)\n",
        "segment_df['pc_coverage'].value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1692188938481
        }
      },
      "id": "83575a59"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Store output"
      ],
      "metadata": {},
      "id": "b59e0994"
    },
    {
      "cell_type": "code",
      "source": [
        "segment_df.to_file(cf.segments_file, driver='GPKG')\n",
        "\n",
        "# Delete intermediate output\n",
        "if os.path.exists(cf.tmp_file):\n",
        "    os.remove(cf.tmp_file)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1692188947944
        }
      },
      "id": "694e3558"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot results"
      ],
      "metadata": {},
      "id": "8db2f148-9c9f-44f9-84f8-100926f57d94"
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: read the saved segments file.\n",
        "segment_df = gpd.read_file(cf.segments_file, crs=cf.CRS)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1692188962321
        }
      },
      "id": "353446ae-b46e-46b0-bc87-15fa8b0380e6"
    },
    {
      "cell_type": "code",
      "source": [
        "#%matplotlib widget\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tilecodes = all_tiles\n",
        "\n",
        "plot_shape = so.unary_union([poly_utils.tilecode_to_poly(tilecode) for tilecode in tilecodes])\n",
        "(x_min, y_min, x_max, y_max) = plot_shape.bounds\n",
        "df_plot = df[df.intersects(plot_shape)]\n",
        "seg_plot = segment_df[segment_df.intersects(plot_shape)]\n",
        "\n",
        "fig, ax = plt.subplots(1, figsize=(6,6))\n",
        "\n",
        "df_plot.set_geometry('geometry').plot(ax=ax, color='grey', alpha=0.5)\n",
        "seg_plot.plot(ax=ax, column='min_width', cmap='Spectral', vmin=0, vmax=3, legend=True)\n",
        "\n",
        "ax.set_xlim([x_min, x_max])\n",
        "ax.set_ylim([y_min, y_max])\n",
        "\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "9f0a9c9e-a02e-4f08-ab34-737a275ed2c8"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "venv_width",
      "language": "python",
      "display_name": "venv_width"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "venv_width"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}