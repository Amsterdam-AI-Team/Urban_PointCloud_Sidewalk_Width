{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4636d31d",
   "metadata": {},
   "source": [
    "# Filter all the points in the point cloud above sidewalk\n",
    "In the previous notebook we scraped and parsed sidewalk data in the form of polygons. With the help of this reference data, we can filter all the points in the point cloud cloud that are above the sidewalk. This preprocessing step is performed in this notebook to reduce the amount of points in the point cloud.\n",
    "\n",
    "If the input point cloud is partly labelled using the [Urban_PointCloud_Processing](https://github.com/Amsterdam-AI-Team/Urban_PointCloud_Processing) project its GROUND and ROAD labels are used to filter ground points; otherwise a separate ground filtering step is performed first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395bd7d8-8e00-4a61-9203-cc8940a0223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project src to path.\n",
    "import set_path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pathlib\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import upcp.fusion as fusion\n",
    "import upcp.utils.ahn_utils as ahn_utils\n",
    "import upcp.utils.las_utils as las_utils\n",
    "from upcp.labels import Labels\n",
    "\n",
    "# Local imports\n",
    "import upc_sw.sw_utils as sw_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc14917-e983-4dd3-92a6-1629907eddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AHN version, either ahn3 or ahn4\n",
    "ahn_version = 'ahn3'\n",
    "\n",
    "# Resume previous incomplete run\n",
    "resume = True\n",
    "\n",
    "# Data folders.\n",
    "base_folder = '../../datasets/Stadsdelen/'\n",
    "ahn_data_folder = '../../datasets/AHN4/ahn4_npz/'\n",
    "bgt_data_file = 'bgt/bgt_voetpad.gpkg'\n",
    "pc_data_folder = 'pointclouds/'\n",
    "\n",
    "tiles_data_file = '../../datasets/Stadsdelen/all_tiles.csv'\n",
    "min_points = 10000\n",
    "\n",
    "use_existing_labels = False\n",
    "\n",
    "# Which stadsdelen to include\n",
    "stadsdelen = ['centrum', 'haven', 'nieuw_west', 'noord', 'oost', 'west', 'zuid', 'zuid_oost']\n",
    "\n",
    "# Max obstacle height to consider\n",
    "max_height_above_ground = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc635969-121c-4890-afae-551a2f087815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AHN elevation reader.\n",
    "ahn_reader = ahn_utils.NPZReader(data_folder=ahn_data_folder, caching=False)\n",
    "\n",
    "# Ground fuser using pre-processed AHN data. Used when no existing labels are available.\n",
    "ground_fuser = fusion.AHNFuser(Labels.GROUND, ahn_reader=ahn_reader,\n",
    "                               target='ground', epsilon=0.2, refine_ground=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c305d44-fe83-4d04-a7c2-a315810705c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders for obstacle files.\n",
    "for stdsdl in stadsdelen:\n",
    "    for run in ['run1', 'run2']:\n",
    "        new_path = pathlib.Path(base_folder) / stdsdl / pc_data_folder / f'obstacles_{run}'\n",
    "        new_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb36c728-f81b-433d-a240-49d58d4ed96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all tilecodes to process.\n",
    "all_tiles_df = pd.read_csv(tiles_data_file)\n",
    "\n",
    "# Filter by number of points.\n",
    "all_tiles_df = all_tiles_df[all_tiles_df['n_points'] >= min_points]\n",
    "\n",
    "# Select those for which we have two runs.\n",
    "all_tiles_df = all_tiles_df.groupby(['stadsdeel', 'tilecode']).filter(lambda x: len(x) == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9e0c8-6ecc-4ed6-95fc-dc4c6838a62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_done(group):\n",
    "    (stdsdl, run) = group.name\n",
    "    done_folder = pathlib.Path(base_folder) / stdsdl / pc_data_folder / f'obstacles_run{run}'\n",
    "    done_tiles = las_utils.get_tilecodes_from_folder(done_folder, las_prefix='obst')\n",
    "    group['done'] = group['tilecode'].isin(done_tiles)\n",
    "    return group\n",
    "\n",
    "if resume:\n",
    "    all_tiles_df['done'] = False\n",
    "    all_tiles_df = all_tiles_df.groupby(['stadsdeel', 'run']).apply(check_done)\n",
    "    n_done = all_tiles_df['done'].sum()\n",
    "    print(f'{n_done} / {len(all_tiles_df)} tiles done')\n",
    "    all_tiles_df = all_tiles_df[~all_tiles_df['done']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6428e637-cc56-4e9e-ba7d-6ac85c245264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sidewalk data.\n",
    "bgt_dict = dict()\n",
    "for stdsdl in all_tiles_df['stadsdeel'].unique():\n",
    "    file = pathlib.Path(base_folder) / stdsdl / bgt_data_file\n",
    "    bgt_dict[stdsdl] = gpd.read_file(file).set_index('ogc_fid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dec7e63-8877-4ed6-873d-ffd43d16d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_tqdm = tqdm(all_tiles_df.groupby(['stadsdeel', 'tilecode']), unit='tile', smoothing=0)\n",
    "for tile in tile_tqdm:\n",
    "    stdsdl = tile[0][0]\n",
    "    tilecode = tile[0][1]\n",
    "    tile_tqdm.set_postfix_str(f'{stdsdl}/{tilecode}')\n",
    "    for run in ['run1', 'run2']:\n",
    "        file = pathlib.Path(base_folder) / stdsdl / pc_data_folder / run / f'filtered_{tilecode}.laz'\n",
    "\n",
    "        # Load pointcloud data.\n",
    "        points, labels = sw_utils.read_las(file, extra_val='label')\n",
    "        obstacle_mask = np.zeros((len(points),), dtype=bool)\n",
    "\n",
    "        # Load ground points.\n",
    "        if use_existing_labels and np.count_nonzero(labels) > 0:\n",
    "            print(f'{tilecode}: using labels found in pointcloud file.')\n",
    "            ground_mask = sw_utils.create_label_mask(labels, target_labels=ground_labels)\n",
    "        else:\n",
    "            mask = np.ones((len(points),), dtype=bool)\n",
    "            ground_mask = ground_fuser.get_label_mask(points, labels, mask, tilecode)\n",
    "\n",
    "        # Extract points aboves sidewalk.\n",
    "        sw_mask, has_polys = sw_utils.sidewalk_clip(\n",
    "                                    points[~ground_mask], tilecode, sw_poly_gdf=bgt_dict[stdsdl],\n",
    "                                    ahn_reader=ahn_reader, max_height=max_height_above_ground)\n",
    "\n",
    "        if has_polys:  # Only save .laz file when sidewalk polys are present\n",
    "            obstacle_mask[~ground_mask] = sw_mask\n",
    "\n",
    "            # Save the new point cloud\n",
    "            out_file = pathlib.Path(base_folder) / stdsdl / pc_data_folder / f'obstacles_{run}' / f'obst_{tilecode}.laz'\n",
    "            sw_utils.write_las(points[obstacle_mask], out_file, values=labels[obstacle_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce07d7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
