{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4636d31d",
   "metadata": {},
   "source": [
    "# Filter all the points in the point cloud above sidewalk\n",
    "In the previous notebook we scraped and parsed sidewalk data in the form of polygons. With the help of this reference data, we can filter all the points in the point cloud cloud that are above the sidewalk. This preprocessing step is performed in this notebook to reduce the amount of points in the point cloud.\n",
    "\n",
    "If the input point cloud is partly labelled using the [Urban_PointCloud_Processing](https://github.com/Amsterdam-AI-Team/Urban_PointCloud_Processing) project its GROUND and ROAD labels are used to filter ground points; otherwise a separate ground filtering step is performed first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395bd7d8-8e00-4a61-9203-cc8940a0223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project src to path.\n",
    "import set_path\n",
    "\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pathlib\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import upcp.fusion as fusion\n",
    "import upcp.utils.ahn_utils as ahn_utils\n",
    "import upcp.utils.las_utils as las_utils\n",
    "from upcp.labels import Labels\n",
    "\n",
    "# Local imports\n",
    "import upc_sw.sw_utils as sw_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc14917-e983-4dd3-92a6-1629907eddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data folders.\n",
    "ahn_data_folder = '../datasets/ahn/ahn3_npz/'\n",
    "bgt_data_file = '../datasets/bgt/bgt_voetpad.gpkg'\n",
    "pc_data_folder = '../datasets/pointclouds/'\n",
    "pc_file_prefix = 'processed'\n",
    "\n",
    "# Use existing labels in the point cloud, if present. Otherwise, perform ground filter step.\n",
    "use_existing_labels = True\n",
    "ground_labels = [Labels.GROUND, Labels.ROAD] # Which labels to use as ground.\n",
    "\n",
    "max_height_above_ground = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc635969-121c-4890-afae-551a2f087815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AHN elevation reader.\n",
    "ahn_reader = ahn_utils.NPZReader(data_folder=ahn_data_folder, caching=False)\n",
    "\n",
    "# Sidewalk polygon reader.\n",
    "sw_gdf = gpd.read_file(bgt_data_file).set_index('ogc_fid')\n",
    "\n",
    "# Ground fuser using pre-processed AHN data. Used when no existing labels are available.\n",
    "ground_fuser = fusion.AHNFuser(Labels.GROUND, ahn_reader=ahn_reader,\n",
    "                               target='ground', epsilon=0.2, refine_ground=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c305d44-fe83-4d04-a7c2-a315810705c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders for obstacle files.\n",
    "for run in ['run1', 'run2']:\n",
    "    new_path = f'{pc_data_folder}obstacles_{run}'\n",
    "    pathlib.Path(new_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2d40dc-9b55-4ae2-9f3f-d9a5cdcf633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all tilecodes for which we have two runs.\n",
    "all_tiles = set(las_utils.get_tilecodes_from_folder(f'{pc_data_folder}run1/', las_prefix=pc_file_prefix)\n",
    "                .intersection(las_utils.get_tilecodes_from_folder(f'{pc_data_folder}run2/', las_prefix=pc_file_prefix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dec7e63-8877-4ed6-873d-ffd43d16d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_tqdm = tqdm(all_tiles, unit='tile', smoothing=0)\n",
    "\n",
    "for tilecode in tile_tqdm:\n",
    "    tile_tqdm.set_postfix_str(tilecode)\n",
    "    print(f'Processing tile {tilecode}...')\n",
    "    for run in ['run1', 'run2']:\n",
    "        file = f'{pc_data_folder}{run}/{pc_file_prefix}_{tilecode}.laz'\n",
    "        \n",
    "        # Load pointcloud data.\n",
    "        points, labels = sw_utils.read_las(file, extra_val='label')\n",
    "        obstacle_mask = np.zeros((len(points),), dtype=bool)\n",
    "        \n",
    "        # Load ground points.\n",
    "        if use_existing_labels and np.count_nonzero(labels) > 0:\n",
    "            print('Using labels found in pointcloud file.')\n",
    "            ground_mask = sw_utils.create_label_mask(labels, target_labels=ground_labels)\n",
    "        else:\n",
    "            mask = np.ones((len(points),), dtype=bool)\n",
    "            ground_mask = ground_fuser.get_label_mask(points, labels, mask, tilecode)\n",
    "        \n",
    "        # Extract points aboves sidewalk.\n",
    "        sw_mask, has_polys = sw_utils.sidewalk_clip(\n",
    "                                    points[~ground_mask], tilecode, sw_poly_gdf=sw_gdf,\n",
    "                                    ahn_reader=ahn_reader, max_height=max_height_above_ground)\n",
    "        \n",
    "        if has_polys:  # Only save .laz file when sidewalk polys are present\n",
    "            obstacle_mask[~ground_mask] = sw_mask\n",
    "\n",
    "            # Save the new point cloud\n",
    "            out_file = f'{pc_data_folder}obstacles_{run}/obst_{tilecode}.laz'\n",
    "            sw_utils.write_las(points[obstacle_mask], out_file, values=labels[obstacle_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce07d7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
